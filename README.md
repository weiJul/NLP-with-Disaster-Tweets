# NLP Disaster Tweets trained on distilbert

In this repo I trained the the fintuned the *distilbert-base-uncased* model from the *transformers* library (https://huggingface.co/) to classify the *Disaster Tweets* (https://www.kaggle.com/c/nlp-getting-started). This model performed an accuracy of 0.84.

## Usage
- Donload th data from [Kaggle](https://www.kaggle.com/c/nlp-getting-started)
- Run *main.py*
- The submission.csv will be generated in the results folder
